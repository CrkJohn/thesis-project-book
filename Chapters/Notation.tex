\chapter*{Notación}
\label{notation}


% Sometimes we have to include the following line to get this section
% included in the Table of Contents despite being a chapter*
\addcontentsline{toc}{chapter}{Notación}

\vspace{\notationgap}
% Need to use minipage to keep title of table on same page as table
{\begin{center} \large Esta notación es una adaptación de la presentada en \cite{deeplearning}.\end{center}}

\begin{minipage}{\textwidth}
% This is a hack to put a little title over the table
% We cannot use "\section*", etc., they appear in the table of contents.
% tocdepth does not work on this chapter.
  
\centerline{\bf Números y Arreglos}
\bgroup
% The \arraystretch definition here increases the space between rows in the table,
% so that \displaystyle math has more vertical space.
\def\arraystretch{1.5}
\begin{tabular}{cp{0.7\textwidth}}
$\displaystyle a$ & Un escalar (entero o real)\\
$\displaystyle \va$ & Un vector\\
$\displaystyle \mA$ & Una matriz\\
% $\displaystyle \tA$ & A tensor\\
$\displaystyle \mI_n$ & Matriz identidad con $n$ filas y $n$ columnas\\
$\displaystyle \mI$ & Matriz identidad con dimensionalidad implícita por el contexto\\
$\displaystyle \ve^{(i)}$ & Vector estándar base $[0,\dots,0,1,0,\dots,0]$ con un 1 en la posición $i$\\
% $\displaystyle \text{diag}(\va)$ & A square, diagonal matrix with diagonal entries given by $\va$\\
$\displaystyle \ra$ & Una variable aleatoria real\\
$\displaystyle \rva$ & Un vector de variables aleatorias\\
$\displaystyle \rmA$ & Una matriz de variables aleatorias\\
\end{tabular}
\egroup
\index{Scalar}
\index{Vector}
\index{Matrix}
\index{Tensor}
\end{minipage}

\vspace{\notationgap}
\begin{minipage}{\textwidth}
\centerline{\bf Conjuntos y Grafos}
\bgroup
\def\arraystretch{1.5}
\begin{tabular}{cp{0.7\textwidth}}
$\displaystyle \sA$ & Un conjunto\\
$\displaystyle \R$ & El conjunto de números reales \\
$\displaystyle \Nat$ & El conjunto de números naturales \\
% NOTE: do not use \R^+, because it is ambiguous whether:
% - It includes 0
% - It includes only real numbers, or also infinity.
% We usually do not include infinity, so we may explicitly write
% [0, \infty) to include 0
% (0, \infty) to not include 0
$\displaystyle \{0, 1\}$ & El conjunto que contiene al 0 y el 1 \\
$\displaystyle \{0, 1, \dots, n \}$ & El conjunto que contiene todos lo números entre $0$ y $n$\\
$\displaystyle [a, b]$ & El intervalo real que incluye $a$ y $b$\\
$\displaystyle (a, b]$ & El intervalo real que no incluye $a$ pero si $b$ \\
$\displaystyle \sA \backslash \sB$ & Substracción de conjuntos, e.g., el conjunto que contiene los elementos de  $\sA$ que no están en $\sB$\\
$\displaystyle \gG$ & Un grafo\\
$\displaystyle \parents_\gG(\ervx_i)$ & El padre de $\ervx_i$ en $\gG$
\end{tabular}
\egroup
\index{Scalar}
\index{Vector}
\index{Matrix}
\index{Tensor}
\index{Graph}
\index{Set}
\end{minipage}

\vspace{\notationgap}
\begin{minipage}{\textwidth}
\centerline{\bf Índices}
\bgroup
\def\arraystretch{1.5}
\begin{tabular}{cp{0.7\textwidth}}
$\displaystyle \eva_i$ & Elemento $i$ del vector $\va$, con índice empezando en 1\\
$\displaystyle \eva_{-i}$ & Todos los elementos del vector $\va$ a excepción del elemento $i$ \\
$\displaystyle \emA_{i,j}$ & Elemento $i, j$ de la matriz $\mA$ \\
$\displaystyle \mA_{i, :}$ & Fila $i$ de la matriz $\mA$ \\
$\displaystyle \mA_{:, i}$ & Columna $i$ de la matriz $\mA$ \\
% $\displaystyle \etA_{i, j, k}$ & Element $(i, j, k)$ of a 3-D tensor $\tA$\\
% $\displaystyle \tA_{:, :, i}$ & 2-D slice of a 3-D tensor\\
$\displaystyle \erva_i$ & Elemento $i$ del vector aleatorio $\rva$ \\
\end{tabular}
\egroup
\end{minipage}

\vspace{\notationgap}
\begin{minipage}{\textwidth}
\centerline{\bf Operaciones de Álgebra Lineal}
\bgroup
\def\arraystretch{1.5}
\begin{tabular}{cp{0.7\textwidth}}
$\displaystyle \mA^\top$ & Traspuesta de la matriz $\mA$ \\
% $\displaystyle \mA^+$ & Moore-Penrose pseudoinverse of $\mA$\\
% $\displaystyle \mA \odot \mB $ & Element-wise (Hadamard) product of $\mA$ and $\mB$ \\
% Wikipedia uses \circ for element-wise multiplication but this could be confused with function composition
$\displaystyle \mathrm{det}(\mA)$ & Determinante de la matriz $\mA$ \\
\end{tabular}
\egroup
\index{Transpose}
\index{Element-wise product|see {Hadamard product}}
\index{Hadamard product}
\index{Determinant}
\end{minipage}

\vspace{\notationgap}
\begin{minipage}{\textwidth}
\centerline{\bf Calculo}
\bgroup
\def\arraystretch{1.5}
\begin{tabular}{cp{0.7\textwidth}}
% NOTE: the [2ex] on the next line adds extra height to that row of the table.
% Without that command, the fraction on the first line is too tall and collides
% with the fraction on the second line.
$\displaystyle\frac{d y} {d x}$ & Derivada de $y$ con respecto a  $x$\\ [2ex]
$\displaystyle \frac{\partial y} {\partial x} $ & Derivada parcial de $y$ con respecto a $x$ \\
$\displaystyle \nabla_\vx y $ & Gradiente de $y$ con respecto a $\vx$ \\
$\displaystyle \nabla_\mX y $ & Matriz de derivadas de $y$ con respecto a $\mX$ \\
% $\displaystyle \nabla_\tX y $ & Tensor containing derivatives of $y$ with respect to $\tX$ \\
% $\displaystyle \frac{\partial f}{\partial \vx} $ & Jacobian matrix $\mJ \in \R^{m\times n}$ of $f: \R^n \rightarrow \R^m$\\
% $\displaystyle \nabla_\vx^2 f(\vx)\text{ or }\mH( f)(\vx)$ & The Hessian matrix of $f$ at input point $\vx$\\
$\displaystyle \int f(\vx) d\vx $ & Integral definida sobre un dominio entero $\vx$ \\
$\displaystyle \int_\sS f(\vx) d\vx$ & Integral definida con respecto a $\vx$ sobre el conjunto $\sS$ \\
\end{tabular}
\egroup
\index{Derivative}
\index{Integral}
\index{Jacobian matrix}
\index{Hessian matrix}
\end{minipage}

\vspace{\notationgap}
\begin{minipage}{\textwidth}
\centerline{\bf Teoría de Probabilidad e Información}
\bgroup
\def\arraystretch{1.5}
\begin{tabular}{cp{0.7\textwidth}}
$\displaystyle \ra \bot \rb$ & Las variables aleatorias $\ra$ y $\rb$ son independientes\\
$\displaystyle \ra \bot \rb \mid \rc $ & Son condicionalmente independientes dado $\rc$\\
$\displaystyle P(\ra)$ & Una distribución de probabilidad de una variable aleatoria discreta\\
$\displaystyle p(\ra)$ & Una distribución de probabilidad de una variable aleatoria continua\\
$\displaystyle \ra \sim P$ & La variable aleatoria $\ra$ tiene distribución $P$\\% so thing on left of \sim should always be a random variable, with name beginning with \r
% $\displaystyle  \E_{\rx\sim P} [ f(x) ]\text{ or } \E f(x)$ & Expectation of $f(x)$ with respect to $P(\rx)$ \\
% $\displaystyle \Var(f(x)) $ &  Variance of $f(x)$ under $P(\rx)$ \\
% $\displaystyle \Cov(f(x),g(x)) $ & Covariance of $f(x)$ and $g(x)$ under $P(\rx)$\\
% $\displaystyle H(\rx) $ & Shannon entropy of the random variable $\rx$\\
% $\displaystyle \KL ( P \Vert Q ) $ & Kullback-Leibler divergence of P and Q \\
$\displaystyle \mathcal{N} ( \vx ; \vmu , \vsigma^2)$ & Distribución gaussiana %
sobre $\vx$ con media $\vmu$ y varianza $\vsigma^2$ \\
\end{tabular}
\egroup
\index{Independence}
\index{Conditional independence}
\index{Variance}
\index{Covariance}
\index{Kullback-Leibler divergence}
\index{Shannon entropy}
\end{minipage}

\vspace{\notationgap}
\begin{minipage}{\textwidth}
\centerline{\bf Funciones}
\bgroup
\def\arraystretch{1.5}
\begin{tabular}{cp{0.7\textwidth}}
$\displaystyle f: \sA \rightarrow \sB$ & La función $f$ con dominio $\sA$ y rango $\sB$\\
$\displaystyle f \circ g $ & Composición de las funciones $f$ y $g$ \\
  $\displaystyle f(\vx ; \vtheta) $ & Una función de $\vx$ parametrizado por $\vtheta$. \\
$\displaystyle \log x$ & Logaritmo natural de $x$ \\
$\displaystyle \sigma(x)$ & Función sigmoid logística, $\displaystyle \frac{1} {1 + \exp(-x)}$ \\
% $\displaystyle \zeta(x)$ & Softplus, $\log(1 + \exp(x))$ \\
$\displaystyle \| \vx \|_p $ & Norma $\normlp$ de $\vx$ \\
$\displaystyle \| \vx \| $ & Norma $\normltwo$ de $\vx$ \\
$\displaystyle x^+$ & Parte positiva de $x$, e.g., $\max(0,x)$\\
$\displaystyle \1_\mathrm{condition}$ & Es 1 si \texttt{condition} es verdadero, 0 de lo contrario\\
\end{tabular}
\egroup
\index{Sigmoid}
\index{Softplus}
\index{Norm}
\end{minipage}

% Sometimes we use a function $f$ whose argument is a scalar but apply
% it to a vector, matrix, or tensor: $f(\vx)$, $f(\mX)$, or $f(\tX)$.
% This denotes the application of $f$ to the
% array element-wise. For example, if $\tC = \sigma(\tX)$, then $\etC_{i,j,k} = \sigma(\etX_{i,j,k})$
% for all valid values of $i$, $j$ and $k$.


\vspace{\notationgap}
\begin{minipage}{\textwidth}
\centerline{\bf Datasets}
\bgroup
\def\arraystretch{1.5}
\begin{tabular}{cp{0.7\textwidth}}
% $\displaystyle \pdata$ & The data generating distribution\\
% $\displaystyle \ptrain$ & The empirical distribution defined by the training set\\
$\displaystyle \sX$ & Un conjunto de muestras de entrenamiento\\
$\displaystyle \vx^{(i)}$ & La $i$-\'esima muestra (entrada) de un Dataset\\
$\displaystyle y^{(i)}\text{ or }\vy^{(i)}$ & El objetivo asociado con $\vx^{(i)}$ para aprendizaje supervisado\\
$\displaystyle \mX$ & La matriz de $m \times n$ con muestra de entrada $\vx^{(i)}$ en la fila $\mX_{i,:}$\\
\end{tabular}
\egroup
\end{minipage}

\clearpage
